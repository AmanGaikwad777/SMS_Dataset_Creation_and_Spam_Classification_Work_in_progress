{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d156aead-a0e9-418c-b93a-121d4a81af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ 502 error on attempt 1 â€” retrying...\n",
      "ðŸŒ 502 error on attempt 1 â€” retrying...\n",
      "ðŸŒ 502 error on attempt 1 â€” retrying...\n",
      "ðŸŒ 502 error on attempt 1 â€” retrying...\n",
      "âœ… Annotated dataset saved successfully: C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_deepseekv3_671b.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. Imports\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "# =======================\n",
    "# 2. Load dataset\n",
    "# =======================\n",
    "df = pd.read_csv(r\"C:\\Users\\amang\\sample_project\\Rishabh_mess.csv\")  # Ensure column: \"message_body\"\n",
    "\n",
    "# =======================\n",
    "# 3. Define label categories\n",
    "# =======================\n",
    "label_categories = [\n",
    "    \"Phishing\",\n",
    "    \"Smishing\",\n",
    "    \"Promotional\",\n",
    "    \"Loan/Financial Scam\",\n",
    "    \"Job Scam\",\n",
    "    \"Crypto/Investment Scam\",\n",
    "    \"No Spam\"\n",
    "]\n",
    "\n",
    "labels_str = \", \".join(label_categories)\n",
    "\n",
    "# =======================\n",
    "# 4. Define a function to classify a single SMS (with confidence)\n",
    "# =======================\n",
    "def classify_sms_with_confidence(text, model=\"deepseek-v3.1:671b-cloud\", retries=3, backoff=2):\n",
    "    prompt = f\"\"\"\n",
    "    You are an SMS classifier. Classify the following SMS into one of these categories:\n",
    "    {labels_str}.\n",
    "    For each label, assign a confidence score between 0 and 1 (sum does not need to be exactly 1).\n",
    "\n",
    "    Return ONLY a valid JSON object â€” no markdown, code fences, or text.\n",
    "    Example output:\n",
    "    {{\n",
    "        \"Phishing\": 0.12,\n",
    "        \"Smishing\": 0.05,\n",
    "        \"Promotional\": 0.60,\n",
    "        \"Loan/Financial Scam\": 0.10,\n",
    "        \"Job Scam\": 0.05,\n",
    "        \"Crypto/Investment Scam\": 0.02,\n",
    "        \"No Spam\": 0.06\n",
    "    }}\n",
    "\n",
    "    SMS: \"{text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            content = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            # ---- Clean possible markdown fences ----\n",
    "            content = re.sub(r\"^```[a-zA-Z0-9]*\", \"\", content).strip(\"` \\n\")\n",
    "\n",
    "            # ---- Try to fix minor JSON issues ----\n",
    "            # e.g., trailing commas, double braces, etc.\n",
    "            content = re.sub(r\",\\s*}\", \"}\", content)\n",
    "            content = re.sub(r\"}\\s*}$\", \"}\", content)\n",
    "\n",
    "            # ---- Parse JSON safely ----\n",
    "            confidences = json.loads(content)\n",
    "\n",
    "            # Ensure all labels exist\n",
    "            for label in label_categories:\n",
    "                confidences.setdefault(label, 0.0)\n",
    "\n",
    "            # ---- Determine top label ----\n",
    "            predicted_label = max(confidences, key=confidences.get)\n",
    "            return predicted_label, confidences\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âš ï¸ Invalid JSON on attempt {attempt}:\\n{content}\")\n",
    "            if attempt == retries:\n",
    "                return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "            time.sleep(backoff * attempt)\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"502\" in str(e):\n",
    "                print(f\"ðŸŒ 502 error on attempt {attempt} â€” retrying...\")\n",
    "                time.sleep(backoff * attempt)\n",
    "                continue\n",
    "            print(\"Error:\", e)\n",
    "            return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "\n",
    "# =======================\n",
    "# 5. Loop over dataset and classify\n",
    "# =======================\n",
    "predicted_labels = []\n",
    "confidence_dicts = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"message_body\"])\n",
    "    label, confidences = classify_sms_with_confidence(text)\n",
    "    predicted_labels.append(label)\n",
    "    confidence_dicts.append(confidences)\n",
    "    time.sleep(0.3)  # small delay to avoid rate limits\n",
    "\n",
    "# =======================\n",
    "# 6. Merge confidence scores into DataFrame\n",
    "# =======================\n",
    "df[\"predicted_label\"] = predicted_labels\n",
    "conf_df = pd.DataFrame(confidence_dicts)\n",
    "df = pd.concat([df, conf_df], axis=1)\n",
    "\n",
    "# =======================\n",
    "# 7. Save annotated dataset\n",
    "# =======================\n",
    "output_path = r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_deepseekv3_671b.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Annotated dataset saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388d17e8-5a95-47aa-bbae-5c115c4fc625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Annotated dataset saved successfully: C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_qwen3_480b.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. Imports\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import json\n",
    "\n",
    "# =======================\n",
    "# 2. Load dataset\n",
    "# =======================\n",
    "df = pd.read_csv(r\"C:\\Users\\amang\\sample_project\\Rishabh_mess.csv\")  # Ensure column: \"message_body\"\n",
    "\n",
    "# =======================\n",
    "# 3. Define label categories\n",
    "# =======================\n",
    "label_categories = [\n",
    "    \"Phishing\",\n",
    "    \"Smishing\",\n",
    "    \"Promotional\",\n",
    "    \"Loan/Financial Scam\",\n",
    "    \"Job Scam\",\n",
    "    \"Crypto/Investment Scam\",\n",
    "    \"No Spam\"\n",
    "]\n",
    "\n",
    "labels_str = \", \".join(label_categories)\n",
    "\n",
    "# =======================\n",
    "# 4. Define a function to classify a single SMS (with confidence)\n",
    "# =======================\n",
    "def classify_sms_with_confidence(text, model=\"qwen3-coder:480b-cloud\", retries=1):\n",
    "    prompt = f\"\"\"\n",
    "    You are an SMS classifier. Classify the following SMS into one of these categories:\n",
    "    {labels_str}.\n",
    "    For each label, assign a confidence score between 0 and 1 (sum does not need to be exactly 1).\n",
    "\n",
    "    Return ONLY a valid JSON object â€” do NOT use markdown code fences, text, or explanations.\n",
    "    Output must look exactly like this example:\n",
    "    {{\n",
    "        \"Phishing\": 0.12,\n",
    "        \"Smishing\": 0.05,\n",
    "        \"Promotional\": 0.60,\n",
    "        \"Loan/Financial Scam\": 0.10,\n",
    "        \"Job Scam\": 0.05,\n",
    "        \"Crypto/Investment Scam\": 0.02,\n",
    "        \"No Spam\": 0.06\n",
    "    }}\n",
    "\n",
    "    SMS: \"{text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            content = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            # ---- Clean the response (remove code fences if present) ----\n",
    "            if content.startswith(\"```\"):\n",
    "                content = content.strip(\"`\")\n",
    "                content = content.replace(\"json\", \"\", 1).strip()\n",
    "\n",
    "            # ---- Parse JSON ----\n",
    "            confidences = json.loads(content)\n",
    "\n",
    "            # Ensure all labels exist in dict\n",
    "            for label in label_categories:\n",
    "                confidences.setdefault(label, 0.0)\n",
    "\n",
    "            # ---- Determine top label ----\n",
    "            predicted_label = max(confidences, key=confidences.get)\n",
    "            return predicted_label, confidences\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âš ï¸ Invalid JSON from model (attempt {attempt+1}): {content}\")\n",
    "            if attempt == retries:\n",
    "                # If all retries fail\n",
    "                return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "\n",
    "# =======================\n",
    "# 5. Loop over dataset and classify\n",
    "# =======================\n",
    "predicted_labels = []\n",
    "confidence_dicts = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"message_body\"])\n",
    "    label, confidences = classify_sms_with_confidence(text)\n",
    "    predicted_labels.append(label)\n",
    "    confidence_dicts.append(confidences)\n",
    "    time.sleep(0.3)  # adjust if needed for rate limits\n",
    "\n",
    "# =======================\n",
    "# 6. Merge confidence scores into DataFrame\n",
    "# =======================\n",
    "df[\"predicted_label\"] = predicted_labels\n",
    "conf_df = pd.DataFrame(confidence_dicts)\n",
    "df = pd.concat([df, conf_df], axis=1)\n",
    "\n",
    "# =======================\n",
    "# 7. Save annotated dataset\n",
    "# =======================\n",
    "output_path = r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_qwen3_480b.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Annotated dataset saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f04d877-2e0a-4138-acb1-7a7041b35ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Annotated dataset saved successfully: C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_20b.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. Imports\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import json\n",
    "\n",
    "# =======================\n",
    "# 2. Load dataset\n",
    "# =======================\n",
    "df = pd.read_csv(r\"C:\\Users\\amang\\sample_project\\Rishabh_mess.csv\")  # Ensure column: \"message_body\"\n",
    "\n",
    "# =======================\n",
    "# 3. Define label categories\n",
    "# =======================\n",
    "label_categories = [\n",
    "    \"Phishing\",\n",
    "    \"Smishing\",\n",
    "    \"Promotional\",\n",
    "    \"Loan/Financial Scam\",\n",
    "    \"Job Scam\",\n",
    "    \"Crypto/Investment Scam\",\n",
    "    \"No Spam\"\n",
    "]\n",
    "\n",
    "labels_str = \", \".join(label_categories)\n",
    "\n",
    "# =======================\n",
    "# 4. Define a function to classify a single SMS (with confidence)\n",
    "# =======================\n",
    "def classify_sms_with_confidence(text, model=\"gpt-oss:20b-cloud\", retries=1):\n",
    "    prompt = f\"\"\"\n",
    "    You are an SMS classifier. Classify the following SMS into one of these categories:\n",
    "    {labels_str}.\n",
    "    For each label, assign a confidence score between 0 and 1 (sum does not need to be exactly 1).\n",
    "\n",
    "    Return ONLY a valid JSON object â€” do NOT use markdown code fences, text, or explanations.\n",
    "    Output must look exactly like this example:\n",
    "    {{\n",
    "        \"Phishing\": 0.12,\n",
    "        \"Smishing\": 0.05,\n",
    "        \"Promotional\": 0.60,\n",
    "        \"Loan/Financial Scam\": 0.10,\n",
    "        \"Job Scam\": 0.05,\n",
    "        \"Crypto/Investment Scam\": 0.02,\n",
    "        \"No Spam\": 0.06\n",
    "    }}\n",
    "\n",
    "    SMS: \"{text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            content = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            # ---- Clean the response (remove code fences if present) ----\n",
    "            if content.startswith(\"```\"):\n",
    "                content = content.strip(\"`\")\n",
    "                content = content.replace(\"json\", \"\", 1).strip()\n",
    "\n",
    "            # ---- Parse JSON ----\n",
    "            confidences = json.loads(content)\n",
    "\n",
    "            # Ensure all labels exist in dict\n",
    "            for label in label_categories:\n",
    "                confidences.setdefault(label, 0.0)\n",
    "\n",
    "            # ---- Determine top label ----\n",
    "            predicted_label = max(confidences, key=confidences.get)\n",
    "            return predicted_label, confidences\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âš ï¸ Invalid JSON from model (attempt {attempt+1}): {content}\")\n",
    "            if attempt == retries:\n",
    "                # If all retries fail\n",
    "                return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "\n",
    "# =======================\n",
    "# 5. Loop over dataset and classify\n",
    "# =======================\n",
    "predicted_labels = []\n",
    "confidence_dicts = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"message_body\"])\n",
    "    label, confidences = classify_sms_with_confidence(text)\n",
    "    predicted_labels.append(label)\n",
    "    confidence_dicts.append(confidences)\n",
    "    time.sleep(0.3)  # adjust if needed for rate limits\n",
    "\n",
    "# =======================\n",
    "# 6. Merge confidence scores into DataFrame\n",
    "# =======================\n",
    "df[\"predicted_label\"] = predicted_labels\n",
    "conf_df = pd.DataFrame(confidence_dicts)\n",
    "df = pd.concat([df, conf_df], axis=1)\n",
    "\n",
    "# =======================\n",
    "# 7. Save annotated dataset\n",
    "# =======================\n",
    "output_path = r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_20b.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Annotated dataset saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbcca88b-a66f-4faf-98e8-2da2cb05e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Annotated dataset saved successfully: C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_120b.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. Imports\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import json\n",
    "\n",
    "# =======================\n",
    "# 2. Load dataset\n",
    "# =======================\n",
    "df = pd.read_csv(r\"C:\\Users\\amang\\sample_project\\Rishabh_mess.csv\")  # Ensure column: \"message_body\"\n",
    "\n",
    "# =======================\n",
    "# 3. Define label categories\n",
    "# =======================\n",
    "label_categories = [\n",
    "    \"Phishing\",\n",
    "    \"Smishing\",\n",
    "    \"Promotional\",\n",
    "    \"Loan/Financial Scam\",\n",
    "    \"Job Scam\",\n",
    "    \"Crypto/Investment Scam\",\n",
    "    \"No Spam\"\n",
    "]\n",
    "\n",
    "labels_str = \", \".join(label_categories)\n",
    "\n",
    "# =======================\n",
    "# 4. Define a function to classify a single SMS (with confidence)\n",
    "# =======================\n",
    "def classify_sms_with_confidence(text, model=\"gpt-oss:120b-cloud\", retries=1):\n",
    "    prompt = f\"\"\"\n",
    "    You are an SMS classifier. Classify the following SMS into one of these categories:\n",
    "    {labels_str}.\n",
    "    For each label, assign a confidence score between 0 and 1 (sum does not need to be exactly 1).\n",
    "\n",
    "    Return ONLY a valid JSON object â€” do NOT use markdown code fences, text, or explanations.\n",
    "    Output must look exactly like this example:\n",
    "    {{\n",
    "        \"Phishing\": 0.12,\n",
    "        \"Smishing\": 0.05,\n",
    "        \"Promotional\": 0.60,\n",
    "        \"Loan/Financial Scam\": 0.10,\n",
    "        \"Job Scam\": 0.05,\n",
    "        \"Crypto/Investment Scam\": 0.02,\n",
    "        \"No Spam\": 0.06\n",
    "    }}\n",
    "\n",
    "    SMS: \"{text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            content = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            # ---- Clean the response (remove code fences if present) ----\n",
    "            if content.startswith(\"```\"):\n",
    "                content = content.strip(\"`\")\n",
    "                content = content.replace(\"json\", \"\", 1).strip()\n",
    "\n",
    "            # ---- Parse JSON ----\n",
    "            confidences = json.loads(content)\n",
    "\n",
    "            # Ensure all labels exist in dict\n",
    "            for label in label_categories:\n",
    "                confidences.setdefault(label, 0.0)\n",
    "\n",
    "            # ---- Determine top label ----\n",
    "            predicted_label = max(confidences, key=confidences.get)\n",
    "            return predicted_label, confidences\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âš ï¸ Invalid JSON from model (attempt {attempt+1}): {content}\")\n",
    "            if attempt == retries:\n",
    "                # If all retries fail\n",
    "                return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return \"No Spam\", {label: 0.0 for label in label_categories}\n",
    "\n",
    "# =======================\n",
    "# 5. Loop over dataset and classify\n",
    "# =======================\n",
    "predicted_labels = []\n",
    "confidence_dicts = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"message_body\"])\n",
    "    label, confidences = classify_sms_with_confidence(text)\n",
    "    predicted_labels.append(label)\n",
    "    confidence_dicts.append(confidences)\n",
    "    time.sleep(0.3)  # adjust if needed for rate limits\n",
    "\n",
    "# =======================\n",
    "# 6. Merge confidence scores into DataFrame\n",
    "# =======================\n",
    "df[\"predicted_label\"] = predicted_labels\n",
    "conf_df = pd.DataFrame(confidence_dicts)\n",
    "df = pd.concat([df, conf_df], axis=1)\n",
    "\n",
    "# =======================\n",
    "# 7. Save annotated dataset\n",
    "# =======================\n",
    "output_path = r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_120b.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Annotated dataset saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1a6855-2892-4f24-be14-bd5654b600d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final prediction dataset saved as: C:\\Users\\amang\\sample_project\\Combination_of_4.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. Imports\n",
    "# =======================\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# =======================\n",
    "# 2. Define file paths\n",
    "# =======================\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_deepseekv3_671b.csv\",\n",
    "    r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_qwen3_480b.csv\",\n",
    "    r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_20b.csv\",\n",
    "    r\"C:\\Users\\amang\\sample_project\\annotated_dataset_with_confidence_gptoss_120b.csv\"\n",
    "]\n",
    "\n",
    "# =======================\n",
    "# 3. Load all datasets\n",
    "# =======================\n",
    "datasets = [pd.read_csv(path) for path in file_paths]\n",
    "\n",
    "# Ensure all datasets have same order of messages\n",
    "for i in range(1, len(datasets)):\n",
    "    if not datasets[i][\"message_body\"].equals(datasets[0][\"message_body\"]):\n",
    "        print(\"âš ï¸ Warning: Message order mismatch! You may need to merge using a common key.\")\n",
    "        break\n",
    "\n",
    "# =======================\n",
    "# 4. Extract label categories\n",
    "# =======================\n",
    "label_columns = [col for col in datasets[0].columns if col not in [\"message_body\", \"predicted_label\"]]\n",
    "\n",
    "# =======================\n",
    "# 5. Combine predictions\n",
    "# =======================\n",
    "final_labels = []\n",
    "final_confidences = []\n",
    "\n",
    "for i in range(len(datasets[0])):\n",
    "    message = datasets[0].loc[i, \"message_body\"]\n",
    "\n",
    "    # Collect predictions from each dataset\n",
    "    preds = [df.loc[i, \"predicted_label\"] for df in datasets]\n",
    "\n",
    "    # Majority voting\n",
    "    label_counts = Counter(preds)\n",
    "    most_common_label, most_common_count = label_counts.most_common(1)[0]\n",
    "\n",
    "    # In case of tie â†’ use average confidence\n",
    "    top_labels = [label for label, count in label_counts.items() if count == most_common_count]\n",
    "\n",
    "    if len(top_labels) > 1:\n",
    "        avg_confidences = {label: 0.0 for label in label_columns}\n",
    "        for df in datasets:\n",
    "            for label in label_columns:\n",
    "                avg_confidences[label] += df.loc[i, label]\n",
    "        # Average\n",
    "        for label in avg_confidences:\n",
    "            avg_confidences[label] /= len(datasets)\n",
    "\n",
    "        # Pick the label with highest avg confidence among tied ones\n",
    "        most_common_label = max(top_labels, key=lambda l: avg_confidences[l])\n",
    "\n",
    "    # Compute final average confidence of the selected label across models\n",
    "    conf_values = [df.loc[i, most_common_label] for df in datasets if most_common_label in df.columns]\n",
    "    final_confidence = sum(conf_values) / len(conf_values)\n",
    "\n",
    "    final_labels.append(most_common_label)\n",
    "    final_confidences.append(final_confidence)\n",
    "\n",
    "# =======================\n",
    "# 6. Build final dataset\n",
    "# =======================\n",
    "final_df = pd.DataFrame({\n",
    "    \"message_body\": datasets[0][\"message_body\"],\n",
    "    \"final_predicted_label\": final_labels,\n",
    "    \"final_confidence\": final_confidences\n",
    "})\n",
    "\n",
    "# =======================\n",
    "# 7. Save final dataset\n",
    "# =======================\n",
    "output_path = r\"C:\\Users\\amang\\sample_project\\Combination_of_4.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Final prediction dataset saved as: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9e35b-c2d2-4578-95ce-0f0131e50b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
